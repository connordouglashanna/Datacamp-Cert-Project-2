xgb.train(
data = xgbDM_train,
max.depth = 5,
objective = "binary:logistic",
watchlist = watchlist,
nrounds = 100,
verbose = 0
)
# obtaining evaluation log
xgb_training$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss),
ntrees.test = which.min(test_logloss))
# test/train split
split <-
initial_split(moped, prop = 0.8, strata = "model")
moped_train <-
training(split)
moped_test <-
testing(split)
# storing vtreat plan
treatplan <- designTreatmentsZ(moped_train, colnames(moped_train), minFraction = 1/10)
# executing treatment
train_treated <-
prepare(treatplan, moped_train) |>
select(-model_catP)
test_treated <-
prepare(treatplan, moped_test)  |>
select(-model_catP)
# model definition/training
logreg_model <-
glm(owned ~ ., data = train_treated, family = "binomial")
logreg_model
# summary of model
summary(logreg_model)
# test model
test_treated$pred <-
predict(logreg_model, test_treated, type = "response")
# saving this dataframe for later
logreg_pred <-
test_treated
# xgboost
# defining dataframes sans outcome
xgb_train <-
train_treated |>
select(-owned) |>
as.matrix()
xgb_test <-
test_treated |>
select(-c(pred, owned)) |>
as.matrix()
# running cross validation to find the ideal parameters
cv <- xgb.cv(data = xgb_train,
label = train_treated$owned,
nrounds = 100,
nfold = 5,
objective = "binary:logistic",
max_depth = 5,
early_stopping_rounds = 5,
verbose = FALSE   # silent
)
# fetching evaluation log
cv$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss_mean),
ntrees.test = which.min(test_logloss_mean))
# checking cross validation results using xgb.train()
# generating appropriate matrices
xgbDM_train <-
xgb.DMatrix(data = xgb_train, label = train_treated$owned)
xgbDM_test <-
xgb.DMatrix(data = xgb_test, label = test_treated$owned)
# generating watchlist
watchlist <-
list(train = xgbDM_train, test = xgbDM_test)
# running xgb.train()
xgb_training <-
xgb.train(
data = xgbDM_train,
max.depth = 5,
objective = "binary:logistic",
watchlist = watchlist,
nrounds = 100,
verbose = 0
)
# obtaining evaluation log
xgb_training$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss),
ntrees.test = which.min(test_logloss))
# test/train split
split <-
initial_split(moped, prop = 0.8)
moped_train <-
training(split)
moped_test <-
testing(split)
# storing vtreat plan
treatplan <- designTreatmentsZ(moped_train, colnames(moped_train), minFraction = 1/10)
# inspecting results
View(treatplan[["scoreFrame"]])
# executing treatment
train_treated <-
prepare(treatplan, moped_train) |>
select(-model_catP)
test_treated <-
prepare(treatplan, moped_test)  |>
select(-model_catP)
# model definition/training
logreg_model <-
glm(owned ~ ., data = train_treated, family = "binomial")
logreg_model
# summary of model
summary(logreg_model)
# test model
test_treated$pred <-
predict(logreg_model, test_treated, type = "response")
# saving this dataframe for later
logreg_pred_nostrat <-
test_treated
# xgboost
# defining dataframes sans outcome
xgb_train <-
train_treated |>
select(-owned) |>
as.matrix()
xgb_test <-
test_treated |>
select(-c(pred, owned)) |>
as.matrix()
# running cross validation to find the ideal parameters
cv <- xgb.cv(data = xgb_train,
label = train_treated$owned,
nrounds = 100,
nfold = 5,
objective = "binary:logistic",
max_depth = 5,
early_stopping_rounds = 5,
verbose = FALSE   # silent
)
# fetching evaluation log
cv$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss_mean),
ntrees.test = which.min(test_logloss_mean))
# checking cross validation results using xgb.train()
# generating appropriate matrices
xgbDM_train <-
xgb.DMatrix(data = xgb_train, label = train_treated$owned)
xgbDM_test <-
xgb.DMatrix(data = xgb_test, label = test_treated$owned)
# generating watchlist
watchlist <-
list(train = xgbDM_train, test = xgbDM_test)
# running xgb.train()
xgb_training <-
xgb.train(
data = xgbDM_train,
max.depth = 5,
objective = "binary:logistic",
watchlist = watchlist,
nrounds = 100,
verbose = 0
)
# obtaining evaluation log
xgb_training$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss),
ntrees.test = which.min(test_logloss))
# fetching evaluation log
cv$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss_mean),
ntrees.test = which.min(test_logloss_mean))
# models without `model`
#####
# test/train split
split <-
moped |>
select(-model) |>
initial_split(prop = 0.8)
moped_train <-
training(split)
moped_test <-
testing(split)
# storing vtreat plan
treatplan <- designTreatmentsZ(moped_train, colnames(moped_train), minFraction = 1/10)
# inspecting results
View(treatplan[["scoreFrame"]])
# executing treatment
train_treated <-
prepare(treatplan, moped_train) |>
select(-model_catP)
# executing treatment
train_treated <-
prepare(treatplan, moped_train)
test_treated <-
prepare(treatplan, moped_test)
# model definition/training
logreg_model <-
glm(owned ~ ., data = train_treated, family = "binomial")
logreg_model
# summary of model
summary(logreg_model)
# test model
test_treated$pred <-
predict(logreg_model, test_treated, type = "response")
# saving this dataframe for later
logreg_pred_nocat <-
test_treated
# xgboost
# defining dataframes sans outcome
xgb_train <-
train_treated |>
select(-owned) |>
as.matrix()
xgb_test <-
test_treated |>
select(-c(pred, owned)) |>
as.matrix()
# running cross validation to find the ideal parameters
cv <- xgb.cv(data = xgb_train,
label = train_treated$owned,
nrounds = 100,
nfold = 5,
objective = "binary:logistic",
max_depth = 5,
early_stopping_rounds = 5,
verbose = FALSE   # silent
)
# fetching evaluation log
cv$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss_mean),
ntrees.test = which.min(test_logloss_mean))
# checking cross validation results using xgb.train()
# generating appropriate matrices
xgbDM_train <-
xgb.DMatrix(data = xgb_train, label = train_treated$owned)
xgbDM_test <-
xgb.DMatrix(data = xgb_test, label = test_treated$owned)
# generating watchlist
watchlist <-
list(train = xgbDM_train, test = xgbDM_test)
# running xgb.train()
xgb_training <-
xgb.train(
data = xgbDM_train,
max.depth = 5,
objective = "binary:logistic",
watchlist = watchlist,
nrounds = 100,
verbose = 0
)
# obtaining evaluation log
xgb_training$evaluation_log |>
summarize(ntrees.train = which.min(train_logloss),
ntrees.test = which.min(test_logloss))
# defining final model
xgb_model <- xgboost(data = xgb_train,
label = train_treated$owned,
objective = "binary:logistic",
max.depth = 5,
nrounds = 15,
verbose = FALSE
)
# predictions
test_treated$pred <-
predict(xgb_model, xgb_test, nrounds = 10)
# saving for evaluation
xgb_pred_nocat <-
test_treated
?xgb.train
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
# models without `model`
#####
# models without `model`
# test/train split
split <-
moped |>
select(-model) |>
initial_split(prop = 0.8)
moped_train <-
training(split)
moped_test <-
testing(split)
# storing new vtreat plan
treatplan_nocat <- designTreatmentsZ(moped_train, colnames(moped_train), minFraction = 1/10)
# inspecting results
View(treatplan[["scoreFrame"]])
# executing treatment
train_treated <-
prepare(treatplan, moped_train)
test_treated <-
prepare(treatplan_nocat, moped_test)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
# summary of model
summary(logreg_model_nocat)
# test model
test_treated$pred <-
predict(logreg_model_nocat, test_treated, type = "response")
# saving this dataframe for later
logreg_pred_nocat <-
test_treated
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
# predictions
test_treated$pred <-
predict(xgb_model_nocat, xgb_test, nrounds = 10)
# saving for evaluation
xgb_pred_nocat <-
test_treated
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
?xgb.cv
?xgb.train
View(moped)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
# inspecting feature importance
(importance_matrix <-
xgb.importance(feature_names = colnames_3,
model = xgb_model_3))
# visualizing feature importance
xgb.plot.importance(importance_matrix[1:14,])
# visualizing feature importance
xgb.plot.importance(importance_matrix[1:11,])
# inspecting feature importance
(importance_matrix <-
xgb.importance(feature_names = colnames_2,
model = xgb_model_2))
# visualizing feature importance
xgb.plot.importance(importance_matrix[1:14,])
# visualizing feature importance
xgb.plot.importance(importance_matrix[1:13,])
# inspecting feature importance
(importance_matrix <-
xgb.importance(feature_names = colnames_1,
model = xgb_model_1))
# visualizing feature importance
xgb.plot.importance(importance_matrix[1:14,])
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
# installing packages
install.packages(c("ggthemes",
"caret",
"xgboost",
"ggforce",
"vtreat",
"WVPlots"))
# Loading packages
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(colorspace)
library(caret)
library(broom)
library(ggrepel)
install.packages(c("ggthemes", "caret", "xgboost", "ggforce", "vtreat", "WVPlots"))
library(xgboost)
library(rsample)
library(forcats)
library(ggforce)
library(vtreat)
library(WVPlots)
library(pROC)
# Importing data from csv
moped <- read_csv("School/datacamp/Datacamp-Cert-Project-2/moped.csv")
# installing packages
#install.packages(c("ggthemes",
"caret",
# installing packages
install.packages(c("ggthemes",
"caret",
"xgboost",
"ggforce",
"vtreat",
"WVPlots"))
# Loading packages
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(colorspace)
library(caret)
library(broom)
library(ggrepel)
library(xgboost)
library(rsample)
library(forcats)
library(ggforce)
library(vtreat)
library(WVPlots)
library(pROC)
# Importing data from csv
moped <- read_csv("School/datacamp/Datacamp-Cert-Project-2/moped.csv")
install.packages(c("ggthemes", "caret", "xgboost", "ggforce", "vtreat", "WVPlots"))
# installing packages
install.packages(c("ggthemes",
"caret",
"xgboost",
"ggforce",
"vtreat",
"WVPlots"))
# Loading packages
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(colorspace)
library(caret)
library(broom)
library(ggrepel)
library(xgboost)
library(rsample)
library(forcats)
library(ggforce)
library(vtreat)
library(WVPlots)
library(pROC)
# Importing data from csv
moped <- read_csv("School/datacamp/Datacamp-Cert-Project-2/moped.csv")
install.packages(c("ggthemes", "caret", "xgboost", "ggforce", "vtreat", "WVPlots"))
source("~/School/datacamp/Datacamp-Cert-Project-2/datacamp cert project2.R", echo=TRUE)
setwd("~/School/datacamp/Datacamp-Cert-Project-2")
# installing packages
install.packages(c("ggthemes",
"caret",
"xgboost",
"ggforce",
"vtreat",
"WVPlots"))
# Loading packages
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(colorspace)
library(caret)
library(broom)
library(ggrepel)
library(xgboost)
library(rsample)
library(forcats)
library(ggforce)
library(vtreat)
library(WVPlots)
library(pROC)
# set wd
setwd("~/School/datacamp/Datacamp-Cert-Project-2")
# Importing data from csv
moped <- read_csv("School/datacamp/Datacamp-Cert-Project-2/moped.csv")
install.packages(c("ggthemes", "caret", "xgboost", "ggforce", "vtreat", "WVPlots"))
# Importing data from csv
moped <- read_csv("moped.csv")
# installing packages
install.packages(c("ggthemes",
"caret",
"xgboost",
"ggforce",
"vtreat",
"WVPlots"))
install.packages(c("ggthemes", "caret", "xgboost", "ggforce", "vtreat", "WVPlots"))
# installing packages
install.packages(c("ggthemes",
"caret",
"xgboost",
"ggforce",
"vtreat",
"WVPlots"))
# Loading packages
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(colorspace)
library(caret)
library(broom)
library(ggrepel)
library(xgboost)
library(rsample)
library(forcats)
library(ggforce)
library(vtreat)
library(WVPlots)
library(pROC)
# set wd
setwd("~/School/datacamp/Datacamp-Cert-Project-2")
# Importing data from csv
moped <- read_csv("moped.csv")
install.packages(c("ggthemes", "caret", "xgboost", "ggforce", "vtreat", "WVPlots"))
# installing packages
#install.packages(c("ggthemes",
#                   "caret",
#                   "xgboost",
#                   "ggforce",
#                   "vtreat",
#                   "WVPlots"))
# Loading packages
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(colorspace)
library(caret)
library(broom)
library(ggrepel)
library(xgboost)
library(rsample)
library(forcats)
library(ggforce)
library(vtreat)
library(WVPlots)
library(pROC)
# set wd
setwd("~/School/datacamp/Datacamp-Cert-Project-2")
# Importing data from csv
moped <- read_csv("moped.csv")
